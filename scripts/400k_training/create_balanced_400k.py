#!/usr/bin/env python3
"""
Emergency Recovery: Create Balanced 400K Dataset

This creates a high-quality 50/50 balanced dataset:
- 200K benign samples
- 200K attack samples (across all 7 types)
- Training time: minutes, not hours
"""

import pandas as pd
import pathlib

# Paths
DATA_DIR = pathlib.Path("data")
PROCESSED_DIR = DATA_DIR / "processed"
COMPREHENSIVE_CSV = PROCESSED_DIR / "comprehensive_splt_features.csv"
BALANCED_CSV = PROCESSED_DIR / "balanced_train_400k.csv"

def create_balanced_dataset():
    """Create balanced 400K dataset."""
    print("ğŸš¨ EMERGENCY RECOVERY: Creating Balanced 400K Dataset")
    print("=" * 60)
    
    # Load comprehensive dataset
    print("Loading comprehensive dataset...")
    df = pd.read_csv(COMPREHENSIVE_CSV)
    print(f"Loaded {len(df):,} samples")
    
    # Separate benign and attacks
    print("Separating benign and attack samples...")
    benign = df[df['label'] == 0]
    attacks = df[df['label'] == 1]
    
    print(f"Benign samples: {len(benign):,}")
    print(f"Attack samples: {len(attacks):,}")
    
    # Create balanced set (200K each)
    print("Creating balanced 50/50 dataset...")
    
    # Sample 200K benign
    if len(benign) >= 200000:
        benign_sample = benign.sample(n=200000, random_state=42)
        print(f"âœ… Sampled 200,000 benign samples")
    else:
        benign_sample = benign
        print(f"âš ï¸ Using all {len(benign)} benign samples (less than 200K)")
    
    # Sample 200K attacks (stratified across attack types)
    if len(attacks) >= 200000:
        # Simple random sampling for now (can be improved later)
        attack_sample = attacks.sample(n=200000, random_state=42)
        print(f"âœ… Sampled 200,000 attack samples")
    else:
        attack_sample = attacks
        print(f"âš ï¸ Using all {len(attacks)} attack samples (less than 200K)")
    
    # Combine and shuffle
    print("Combining and shuffling...")
    balanced_df = pd.concat([benign_sample, attack_sample], ignore_index=True)
    balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)
    
    # Save balanced dataset
    print(f"Saving balanced dataset to {BALANCED_CSV}")
    BALANCED_CSV.parent.mkdir(parents=True, exist_ok=True)
    balanced_df.to_csv(BALANCED_CSV, index=False)
    
    # Statistics
    print(f"\nğŸ“Š BALANCED DATASET STATISTICS:")
    print(f"Total samples: {len(balanced_df):,}")
    print(f"Benign samples: {len(balanced_df[balanced_df['label'] == 0]):,}")
    print(f"Attack samples: {len(balanced_df[balanced_df['label'] == 1]):,}")
    print(f"Balance ratio: {len(balanced_df[balanced_df['label'] == 0]) / len(balanced_df):.1%}")
    
    if 'pcap_file' in balanced_df.columns:
        print(f"\nğŸ¯ Attack Type Distribution:")
        attack_dist = balanced_df[balanced_df['label'] == 1]['pcap_file'].value_counts()
        for attack, count in attack_dist.items():
            print(f"  {attack}: {count:,} samples")
    
    print(f"\nâœ… Balanced dataset ready!")
    print(f"ğŸš€ Training will now take MINUTES, not hours!")
    print(f"ğŸ“ˆ Expected training time: ~10-15 minutes")
    print(f"ğŸ¯ Expected benign accuracy: 80-95%")
    
    return balanced_df

if __name__ == "__main__":
    create_balanced_dataset()
